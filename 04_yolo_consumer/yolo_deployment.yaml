apiVersion: v1
kind: Namespace
metadata:
  labels:
    pod-security.kubernetes.io/warn: privileged
    pod-security.kubernetes.io/warn-version: latest
  name: workloadb
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: yolo-consumer
  namespace: workloadb
spec:
  selector:
    matchLabels:
      run: yolo-consumer
  template:
    metadata:
      labels:
        run: yolo-consumer
    spec:
      containers:	
      - name: yolo-consumer
        image: roopekettunen/workload_consumer_vino:latest
        imagePullPolicy: Always
        ports:
          - containerPort: 80
        env:

          # VALIDATE YOLO RESULTS OR NOT?
          - name: VALIDATE_RESULTS
            value: "TRUE"

          # DEFINE WHAT YOLO MODEL TO USE
          - name: YOLO_MODEL
            # value: "yolov8n"
            value: "custom-120k"
            # value: "custom-300k"
            # value: "custom-750k"
            # value: "yolov5n"
            # value: "yolov5m"
            # value: "yolov5s"
          - name: OPEN_VINO
            value: "TRUE"

        # THORTTLE CONTAINERS OR NAH?
        # FEW LARGER PROCESSES, OR MANY SMALL ONES?
        # TECHNICALLY, THE END RESULT SHOULD BE THE SAME WITH KAFKA ROUTING
        resources:

          # MAXIMUM RESOURCE LIMIT FOR POD
          limits:
            cpu: 1000m
          
          # MINIMUM RESOURCE REQUIREMENT FOR POD
          requests:
            cpu: 1000m
---
apiVersion: v1
kind: Service
metadata:
  name: yolo-consumer
  namespace: workloadb
  labels:
    run: yolo-consumer
spec:
  ports:
  - port: 80
  selector:
    run: yolo-consumer
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: yolo-consumer
  namespace: workloadb
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: yolo-consumer

  # DETERMINE MAX REPLICAS BASED ON THOTTLED RESOURCES
  # 1 CORE PER POD, 20 PODS TOTAL = MAX 20 REPLICAS
  minReplicas: 6
  maxReplicas: 6
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization

        # HIGH PERCENTAGE = SCALE SLOWER
        # LOW PERCENTAGE = SCALE FASTER
        averageUtilization: 80

  # DEPENDENT ON METRICS SERVER INTERVAL (>=10s)
  # ADD 10-20% BUFFER TO MAKE SURE METRICS SERVER IS FRESH?
  behavior:

    # MINIMUM 10 SECONDS, BUT SHOULD PROBABLY BE 60+ SECONDS FOR STABILITY
    # STRATEGY: SCALE UP FAST WHEN NECESSARY, BUT SCALE DOWN SLOWLY FOR STABILITY?
    scaleDown:
      stabilizationWindowSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 10
